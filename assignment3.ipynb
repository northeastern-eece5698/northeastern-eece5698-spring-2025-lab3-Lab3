{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda9c19-efe9-4f91-ba07-7f7c8060f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import rawpy\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42e07a-672f-4308-9ddb-06a335ab8854",
   "metadata": {},
   "source": [
    "# Programming Assignment 3\n",
    "## Due Date: 23:59, April 9th\n",
    "## Name: YOUR NAME HERE\n",
    "\n",
    "In this programming assignment you will complete an image signal processing pipeline.\n",
    "\n",
    "## Instructions\n",
    "1. Please write your name above in the Name field below the due date.\n",
    "2. Please modify the `demosaic` function. A correct demosaicing function implementation is worth **10 points**.\n",
    "3. You MAY NOT use any external libraries to implement demosaicing or tone mapping.\n",
    "4. Do not touch any other portions of the code!\n",
    "\n",
    "## What and how to submit\n",
    "Please run the **entirety of the Jupyter Notebook**.\n",
    "Even if you haven't implemented the `tone_mapping` function, the Jupyter Notebook should still generate images.\n",
    "Submit _just_ the Jupyter Notebook to Canvas by the due date.\n",
    "Please _do not_ submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ea88a-d580-4fed-a4ce-7829db02ee50",
   "metadata": {},
   "source": [
    "## Pipeline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f1b60-85aa-46b6-92a2-09d86658eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(input_image_path: str) -> rawpy.RawPy:\n",
    "    \"\"\"\n",
    "    Reads a raw image at a specified path\n",
    "    \"\"\"\n",
    "    return rawpy.imread(input_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530d321-d2e5-4279-9124-c6dda0bf9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(raw: rawpy.RawPy) -> np.ndarray:\n",
    "    # raw.raw_colors raw_colors is a numerical mask; we instead generate a char mask so that we can check R/G/B by names\n",
    "\n",
    "    # This is based on spatial raster order on the CFA; 01/32 on iPhone; 23/10 on Pixel\n",
    "    cfa_pattern_id = np.array(raw.raw_pattern)\n",
    "\n",
    "    # This is baesd on numerical order above; RGBG on iPhone; RGBG on Pixel; \n",
    "    color_desc = np.frombuffer(raw.color_desc, dtype=np.byte)\n",
    "\n",
    "    # This tile is based on the raster order\n",
    "    # https://stackoverflow.com/questions/14639496/how-to-create-a-numpy-array-of-arbitrary-length-strings\n",
    "    tile_pattern = np.array([[chr(color_desc[cfa_pattern_id[0, 0]]), chr(color_desc[cfa_pattern_id[0, 1]])],\n",
    "                             [chr(color_desc[cfa_pattern_id[1, 0]]), chr(color_desc[cfa_pattern_id[1, 1]])]], dtype=object)\n",
    "    cfa_pattern_rgb = np.array(tile_pattern, copy=True) # make a deep copy\n",
    "\n",
    "    return cfa_pattern_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b25db8-a5ca-4943-8400-21c7e321c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_bl_norm(raw: rawpy.RawPy) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Subtract black level and normalize\n",
    "    \"\"\"\n",
    "    black = np.reshape(raw.black_level_per_channel, (2, 2))\n",
    "    black = np.tile(black, (raw.raw_image.shape[0]//2, raw.raw_image.shape[1]//2))\n",
    "    return (raw.raw_image - black) / (raw.white_level - black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9603891-8044-4f35-bd4e-27472b84d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demosaic(greyscale_img: np.ndarray, cfa_pattern_rgb: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    ### Implement your demosaicing algorithm here! ###\n",
    "    \n",
    "    ##################################################\n",
    "\n",
    "    return demosaic_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515ddb1-d558-484b-93f5-b50eaed2686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wb_cc(raw: rawpy.RawPy, demosaic_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply white balance and color correction\n",
    "    \"\"\"\n",
    "    \n",
    "    # https://www.pythoninformer.com/python-libraries/numpy/index-and-slice/\n",
    "    # form a Nx3 array from the image pixels\n",
    "    flat_img = np.stack((demosaic_img[:,:,0].flatten(),\n",
    "                         demosaic_img[:,:,1].flatten(),\n",
    "                         demosaic_img[:,:,2].flatten()))\n",
    "    \n",
    "    # White Balance\n",
    "    wb_mat = np.array([[raw.camera_whitebalance[0], 0, 0],\n",
    "                       [0, raw.camera_whitebalance[1], 0],\n",
    "                       [0, 0, raw.camera_whitebalance[2]]])\n",
    "    flat_img = np.matmul(wb_mat, flat_img)\n",
    "    \n",
    "    # Color Correction\n",
    "    cc_mat = raw.color_matrix[0:3, 0:3]\n",
    "    \n",
    "    flat_img = np.clip(np.matmul(cc_mat, flat_img), 0, 1)\n",
    "\n",
    "    \n",
    "    color_img = np.stack((flat_img[0].reshape(raw.raw_image.shape[0], raw.raw_image.shape[1]),\n",
    "                               flat_img[1].reshape(raw.raw_image.shape[0], raw.raw_image.shape[1]),\n",
    "                               flat_img[2].reshape(raw.raw_image.shape[0], raw.raw_image.shape[1])), axis=2)\n",
    "    return color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036766d-e43c-4093-86fa-3794a9a736fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_mapping(color_img: np.ndarray) -> np.ndarray:\n",
     "    \n",
    "    '''\n",
    "    Apply tone mapping\n",
    "    '''\n",
    "    # Reinhard E, Stark M, Shirley P, et al. Photographic tone reproduction for digital images[M]//Seminal Graphics Papers: Pushing the Boundaries, Volume 2. 2023: 661-670.\n",
    "    # https://dl.acm.org/doi/pdf/10.1145/566654.566575\n",
    "\n",
    "    Lw = 0.22\n",
    "\n",
    "    return np.clip(color_img * (1 + color_img / (Lw ** 2)) / (1 + color_img), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413283ec-c1a0-4208-8cee-3b021e9c2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma(color_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply gamma curve\n",
    "    \"\"\"\n",
    "    \n",
    "    i = color_img < 0.0031308\n",
    "    j = np.logical_not(i)\n",
    "    color_img[i] = 323 / 25 * color_img[i]\n",
    "    color_img[j] = 211 / 200 * color_img[j] ** (5 / 12) - 11 / 200\n",
    "    \n",
    "    return color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725d07e-3c19-48f1-a1a7-160d86b529c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(color_img: np.ndarray):\n",
    "    \"\"\"\n",
    "    Displays final image on Jupyter notebook\n",
    "    \"\"\"\n",
    "    display(Image.fromarray((color_img * 256).astype(np.uint8), 'RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa15e5-c86e-4116-9441-1f3f40d4b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(input_image_path: str):\n",
    "    \"\"\"\n",
    "    Run an image through the entire pipeline\n",
    "    \"\"\"\n",
    "    raw = read_image(input_image_path)\n",
    "    cfa_pattern_rgb = extract_metadata(raw)\n",
    "    greyscale_img = subtract_bl_norm(raw)\n",
    "    demosaic_img = demosaic(greyscale_img, cfa_pattern_rgb)\n",
    "    color_img = apply_wb_cc(raw, demosaic_img)\n",
    "    color_img = tone_mapping(color_img)\n",
    "    color_img = apply_gamma(color_img)\n",
    "    display_image(color_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670a880-ce4e-4939-aa7d-1997711e1ae1",
   "metadata": {},
   "source": [
    "## Display Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f53e5-90d1-41ec-a136-d343222f106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('person.dng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e77d0-7398-46fc-a7fb-e0d6e244b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('flower.dng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15e333-ab8e-4ec2-98b9-4bf98f8c925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('tree.dng')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
